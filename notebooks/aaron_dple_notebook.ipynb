{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Perfect-model predictability Module Demo\n",
    "\n",
    "Aaron Spring and Riley Brady\n",
    "\n",
    "---\n",
    "\n",
    "This demo demonstrates the capabilities of the prediction module for a decadal prediction hindcast ensemble.\n",
    "\n",
    "Input:\n",
    "- 1-dimensional xr.Dataset timeseries output\n",
    "\n",
    "Shows:\n",
    "- Skill score (ACC, RMSE) after removing trend\n",
    "---\n",
    "Status:\n",
    "- first small demo so far\n",
    "\n",
    "Questions:\n",
    "- Where to handle detrending? outside hindcast_compute\n",
    "- How to handle detrending? So far removes linear trend. (Also depends how input data anomaly was obtained. How?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from esmtools.prediction import (_pearson_r, _rmse, xr_predictability_horizon)\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "import seaborn as sb\n",
    "from esmtools.stats import xr_linregress\n",
    "import esmtools.stats"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load sample data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assimilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "assim = xr.open_dataset('../sample_data/prediction/g.e11_LENS.GECOIAF.T62_g16.009.pop.h.SST.024901-031612.nc')\n",
    "assim = assim.drop(['z_t','time_bound'])\n",
    "assim = assim.groupby('time.year').mean('time')\n",
    "# create anomaly as DPLE\n",
    "assim = assim - assim.mean('year')\n",
    "assim = assim.rename({'year':'ensemble'})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DPLE\n",
    "CESM Decadal Prediction Large Ensemble http://www.cesm.ucar.edu/projects/community-projects/DPLE/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "varname='SST'\n",
    "DPLE = xr.open_dataset('../sample_data/prediction/CESM-DP-LE.SST.annmean.anom.nc').rename({'anom':'SST'})\n",
    "DPLE = DPLE.rename({'S':'ensemble','M':'member','L':'time'})\n",
    "DPLE_mean = DPLE.mean('member')\n",
    "DPLE.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SST ensemble member mean: Lead year vs ensemble initialization year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DPLE_mean[varname].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lead Year 1 timeseries for all members"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DPLE.sel(time=1).to_dataframe()[varname].unstack().plot(legend=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ensemble member mean timeseries for all lead years"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DPLE.mean('member').to_dataframe()[varname].unstack().plot()\n",
    "assim[varname].plot(lw=3,color='k')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rename to match ensemble, member, year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DPLE = DPLE.sel(ensemble=slice(1955,2015))\n",
    "assim=assim.sel(ensemble=slice(1955,2015))\n",
    "DPE=DPLE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction module for hindcasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the comparison functions are basically the same as xr.broadcast (I want \n",
    "# to have forecast and truth in the same dimensions), but it this\n",
    "# implementation here runs at double speed compared to xr.broadcast\n",
    "\n",
    "def _e2a(DPE, assim):\n",
    "    \"\"\"Compare ensemble member mean forecast with assimilation.\"\"\"\n",
    "    fct = DPE.mean('member')\n",
    "    truth = assim.expand_dims('time')\n",
    "    ntime = DPE.time.size\n",
    "    truth = truth.isel(time=[0]*ntime)\n",
    "    truth['time'] = np.arange(1,1+ntime)\n",
    "    return fct, truth\n",
    "\n",
    "def _m2a(DPE, assim):\n",
    "    \"\"\"Compare every ensemble member forecast with assimilation.\"\"\"\n",
    "    fct = DPE\n",
    "    truth = assim.expand_dims('time').expand_dims('member')\n",
    "    ntime = DPE.time.size\n",
    "    nmember = DPE.member.size\n",
    "    truth = truth.isel(member=[0]*nmember,time=[0]*ntime)\n",
    "    truth['time'] = np.arange(1,1+ntime)\n",
    "    truth['member'] = np.arange(1,1+nmember)\n",
    "    return fct, truth\n",
    "\n",
    "def hindcast_compute(DPE, assim, metric=_pearson_r, comparison=_e2a, time_dim='ensemble'):\n",
    "    \"\"\"\n",
    "    Compute a predictability skill score for a perfect-model framework simulation dataset.\n",
    "\n",
    "    Relies on two concepts yielding equal results (see comparisons):\n",
    "    - np vectorized from xskillscore (_rmse, _pearson_r) but manually 'stacked' (_m2m, m2e, ...)\n",
    "    - xarray vectorized (_mse, _rmse_v, ...) from ensemble variance (_ens_var_against_mean, _..control)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    DPE, assim : Decadal Prediction Ensemble and Assimilation xr.Dataset with\n",
    "                 time_dim dimension (optional spatial coordinates)\n",
    "        input data\n",
    "    metric : function\n",
    "        metric from [_rmse, _pearson_r]\n",
    "    comparison : function\n",
    "        comparison from [_m2a, _e2a]\n",
    "    time_dim : str\n",
    "        Name of the time dimension (likely 'year' or 'time')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    res : xr.DataArray or xr.Dataset\n",
    "        skill score\n",
    "    \"\"\"\n",
    "    if comparison.__name__ not in ['_e2a', '_m2a']:\n",
    "        raise ValueError('specify comparison argument')\n",
    "\n",
    "    if metric.__name__ in ['_pearson_r', '_rmse']:\n",
    "        fct, truth = comparison(DPE,assim)\n",
    "        res = metric(fct, truth,'ensemble')\n",
    "        if comparison.__name__ is '_m2a':\n",
    "            res = res.mean('member')\n",
    "        return res\n",
    "    else:\n",
    "        raise ValueError('specify metric argument')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach for bootstrapping: Shuffle ensemble dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shuffle_ensembles(DPE):\n",
    "    \"\"\"Shuffle ensemble dimension for bootstrapping.\"\"\"\n",
    "    enslist = DPE.ensemble.values\n",
    "    ens = enslist.copy()\n",
    "    np.random.sample(enslist)\n",
    "    DPE_shuffled = DPE.sel(ensemble=enslist)\n",
    "    DPE_shuffled['ensemble'] = ens\n",
    "    return DPE_shuffled\n",
    "\n",
    "import random\n",
    "def _shuffle(ds,dim='ensemble'):\n",
    "    dimval = ds[dim].values\n",
    "    dimval_new = np.random.permutation(dimval)\n",
    "    ds_shuffled = ds.sel({dim:dimval_new})\n",
    "    if isinstance(ds_shuffled,xr.Dataset):\n",
    "        ds_shuffled = ds_shuffled.assign({dim:dimval})\n",
    "    elif isinstance(ds_shuffled,xr.DataArray):\n",
    "        ds_shuffled[dim] = dimval\n",
    "    return ds_shuffled\n",
    "\n",
    "def hindcast_sig(DPE, assim, metric=_pearson_r, comparison=_e2a, sig=99, bootstrap=300):\n",
    "    \"\"\"\n",
    "    Return sig-th percentile of function to be choosen from shuffled DPE.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    DPE, assim : xr.DataArray/Dataset with time_dim dimension\n",
    "        input data\n",
    "    sig: int or list\n",
    "        Significance level for bootstrapping from pseudo ensemble\n",
    "    bootstrap: int\n",
    "        number of iterations\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sig_level : xr.DataArray/Dataset as inputs\n",
    "        significance level without time_dim, ensemble and member dimensions\n",
    "        as many sig_level as listitems in sig\n",
    "\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    for _ in range(1 + int(bootstrap / DPE['time'].size)):\n",
    "        ds_pseudo = _shuffle(DPE)\n",
    "        ds_pseudo_metric = hindcast_compute(\n",
    "            ds_pseudo, assim, metric=metric, comparison=comparison)\n",
    "        x.append(ds_pseudo_metric)\n",
    "    ds_pseudo_metric = xr.concat(x, dim='it')\n",
    "    if isinstance(sig, list):\n",
    "        qsig = [x / 100 for x in sig]\n",
    "    else:\n",
    "        qsig = sig / 100\n",
    "    sig_level = ds_pseudo_metric.quantile(q=qsig, dim=['time', 'it'])\n",
    "    return sig_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_limit_sig(metric=_pearson_r,sig=99):\n",
    "    if metric.__name__ in ['_pearson_r', '_PPP', '_PM_MSSS']:\n",
    "        limit = 'upper'\n",
    "        sigl = sig\n",
    "    else:\n",
    "        limit = 'lower'\n",
    "        sigl = 100 - sig\n",
    "    return limit, sigl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "---\n",
    "- I think we are making our coding very difficult with the time_dim argument. Isnt it much easier if we just agree whether to use time or year? Independent of the choice we make, do we need to have this flexible? To me it seems much easier to rename dimensions in the beginning and then just run the code.\n",
    "- Now this code can only compute the metrics ACC and RMSE because those are implemented based on numpy in xskillscore https://github.com/raybellwaves/xskillscore. \n",
    "    - What do you think about adding the few needed metrics by ourselves? MSE, MAE can be probably easily adapted from this.\n",
    "- So far the rest of the prediction module works always on xr.Datasets (and mostly also for xr.DataArrays). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap=1000\n",
    "sig=99\n",
    "metric=_pearson_r\n",
    "comparison=_e2a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raw anomaly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DPE.mean('member').to_dataframe()[varname].unstack().plot()\n",
    "assim[varname].plot(lw=3,color='k',label='Assimilation')\n",
    "plt.title('Lead year timeseries and assimilation without removing trend')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill = hindcast_compute(DPE, assim, metric=metric,comparison=comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in [_pearson_r,_rmse]:\n",
    "    limit, sigl = get_limit_sig(metric=metric, sig=sig)\n",
    "    for comparison in [_e2a,_m2a]:\n",
    "        # compute hindcast skill\n",
    "        skill = hindcast_compute(DPE, assim,metric=metric,comparison=comparison)\n",
    "        skill[varname].plot(label=' '+metric.__name__+' '+comparison.__name__)\n",
    "        # bootstrap threshold\n",
    "        threshold = hindcast_sig(DPE,assim, metric=metric,comparison=comparison, bootstrap=bootstrap, sig=sigl)[varname].values\n",
    "        plt.axhline(y=threshold, ls=':',c='gray',label='bootstrap n='+str(bootstrap)+' threshold '+str(sig)+'% significance')\n",
    "        ph = xr_predictability_horizon(skill, threshold, limit=limit)[varname].values\n",
    "        plt.axvline(x=ph,ls='-.',c='gray',label='Predictability Horizon')\n",
    "    plt.legend()\n",
    "    plt.title(metric.__name__+' Skill Score without removing trend')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quite high (artificial) ACC prediction skill due to climate change forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detrend by linear fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1\n",
    "detrended_DPE = esmtools.stats.xr_rm_poly(DPE[varname],n, dim='ensemble').to_dataset(varname)\n",
    "detrended_assim = esmtools.stats.xr_rm_poly(assim[varname],n, dim='ensemble').to_dataset(varname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detrended_DPE.mean('member').to_dataframe()[varname].unstack().plot()\n",
    "detrended_assim.to_dataframe()[varname].plot(lw=3,color='k',label='Assimilation')\n",
    "plt.legend()\n",
    "plt.title('Lead year timeseries and assimilation after removing linear trend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probably a 2nd order polynomial does better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in [_pearson_r,_rmse]:\n",
    "    limit, sigl = get_limit_sig(metric=metric, sig=sig)\n",
    "    for comparison in [_e2a,_m2a]:\n",
    "        # compute hindcast skill\n",
    "        skill = hindcast_compute(detrended_DPE, detrended_assim,metric=metric,comparison=comparison)\n",
    "        skill[varname].plot(label=' '+metric.__name__+' '+comparison.__name__)\n",
    "        # bootstrap threshold\n",
    "        threshold = hindcast_sig(detrended_DPE,detrended_assim, metric=metric, comparison=comparison, bootstrap=bootstrap, sig=sigl)[varname].values\n",
    "        plt.axhline(y=threshold, ls=':',c='gray',label='bootstrap n='+str(bootstrap)+' threshold '+str(sig)+'% significance')\n",
    "        ph = xr_predictability_horizon(skill, threshold, limit=limit)[varname].values\n",
    "        plt.axvline(x=ph,ls='-.',c='gray',label='Predictability Horizon')\n",
    "    plt.legend()\n",
    "    plt.title(metric.__name__+' Skill Score after removing linear trend')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detrend via n-th order polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2\n",
    "polyndetrended_DPE = esmtools.stats.xr_rm_poly(DPE[varname],n, dim='ensemble').to_dataset(varname)\n",
    "polyndetrended_assim = esmtools.stats.xr_rm_poly(assim[varname],n, dim='ensemble').to_dataset(varname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyndetrended_DPE.mean('member').to_dataframe()[varname].unstack().plot()\n",
    "detrended_assim.to_dataframe()[varname].plot(lw=3,color='k',label='Assimilation')\n",
    "plt.legend()\n",
    "plt.title('Lead year timeseries and assimilation after removing n-th order polynomial trend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in [_pearson_r,_rmse]:\n",
    "    limit, sigl = get_limit_sig(metric=metric, sig=sig)\n",
    "    for comparison in [_e2a,_m2a]:\n",
    "        # compute hindcast skill\n",
    "        skill = hindcast_compute(polyndetrended_DPE, polyndetrended_assim,metric=metric,comparison=comparison)\n",
    "        skill[varname].plot(label=' '+metric.__name__+' '+comparison.__name__)\n",
    "        # bootstrap threshold\n",
    "        threshold = hindcast_sig(polyndetrended_DPE, polyndetrended_assim, metric=metric, comparison=comparison, bootstrap=bootstrap, sig=sigl)[varname].values\n",
    "        plt.axhline(y=threshold, ls=':',c='gray',label='bootstrap n='+str(bootstrap)+' threshold '+str(sig)+'% significance')\n",
    "        ph = xr_predictability_horizon(skill, threshold, limit=limit)[varname].values\n",
    "        plt.axvline(x=ph,ls='-.',c='gray',label='Predictability Horizon')\n",
    "    plt.legend()\n",
    "    plt.title(metric.__name__+' Skill Score after removing linear trend')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  detrend via unitialised ensemble mean from CESM LE \n",
    "that should be nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
