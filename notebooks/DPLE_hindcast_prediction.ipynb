{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hindcast/Assimilation Prediction Demo\n",
    "\n",
    "Aaron Spring and Riley Brady\n",
    "\n",
    "---\n",
    "\n",
    "This demo demonstrates the capabilities of the prediction module for a decadal prediction hindcast ensemble. This differs from the \"perfect-model\" approach of, e.g., the MPI decadal prediction system. For a perfect-model approach, see `perfect-model_predictability.ipynb`.\n",
    "\n",
    "\n",
    "## Language\n",
    "\n",
    "---\n",
    "\n",
    "Language in the decadal prediction community is nuanced (see reference 3). It is important to distinguish the basic metrics of predictability for a hindcast/assimilation-based system. What are we comparing the actual DPLE to?\n",
    "\n",
    "`predictability` : The DPLE ensemble mean correlated with the hindcast. The DPLE was initialized from the hindcast, but is integrated forward as a freely coupled model. This correlation coefficient (at various leads) communicates the *potential* for the climate system to be predicted. Note that one can also correlate an uninitialized ensemble (e.g., the CESM-LENS) to the hindcast to see how well an initialized ensemble does relative to an uninitialized one.\n",
    "\n",
    "`skill` : The DPLE ensemble mean correlated to observations. How well does the initialized ensemble do at predicting the real world?\n",
    "\n",
    "`persistence` : The hindcast lag-correlated to itself. This is a persistence prediction, i.e., predicting that next month/year will be the same as the last. This communicates whether investment into the DPLE is even worth it. For some systems/regions, persistence is plenty skillful. \n",
    "\n",
    "## Outline\n",
    "\n",
    "---\n",
    "\n",
    "\n",
    "## References\n",
    "\n",
    "---\n",
    "\n",
    "1. **Official manuscript of the CESM-DPLE release:** Yeager, S. G., et al. \"Predicting near-term changes in the Earth System: A large ensemble of initialized decadal prediction simulations using the Community Earth System Model.\" Bulletin of the American Meteorological Society 2018 (2018). \n",
    "\n",
    "\n",
    "2. **Applied case of the DPLE on air-sea CO$_{2}$ fluxes:** Lovenduski, N. S., Yeager, S. G., Lindsay, K., and Long, M. C.: Predicting near-term changes in ocean carbon uptake, Earth Syst. Dynam. Discuss., https://doi.org/10.5194/esd-2018-73, in review, 2018. \n",
    "\n",
    "\n",
    "3. **Broad overview of decadal climate prediction and terminology:** Meehl, Gerald A., et al. \"Decadal climate prediction: an update from the trenches.\" Bulletin of the American Meteorological Society 95.2 (2014): 243-267."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Input:\n",
    "- 1-dimensional xr.Dataset timeseries output\n",
    "\n",
    "Shows:\n",
    "- Skill score (ACC, RMSE) after removing trend\n",
    "\n",
    "---\n",
    "\n",
    "Status:\n",
    "- first small demo so far\n",
    "\n",
    "Questions:\n",
    "- Where to handle detrending? outside hindcast_compute\n",
    "- How to handle detrending? So far removes linear trend. (Also depends how input data anomaly was obtained. How?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'proplot'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-5b389f5b12b6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mesmtools\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstats\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxr_linregress\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmpl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mproplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplot\u001b[0m \u001b[0;31m# Nice viz package\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'proplot'"
     ]
    }
   ],
   "source": [
    "from esmtools.prediction import (_pearson_r, _rmse, xr_predictability_horizon)\n",
    "import matplotlib.pyplot as plt\n",
    "import xarray as xr\n",
    "import numpy as np\n",
    "#import seaborn as sb\n",
    "from esmtools.stats import xr_linregress\n",
    "import matplotlib as mpl\n",
    "import proplot as plot # Nice viz package"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this demo, I'm using `proplot` from https://github.com/lukelbd/proplot. If you're compiling this notebook on your own, you need to run `plot.install_fonts()` and then restart your notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot.nbsetup()\n",
    "# Set global settings\n",
    "def set_aeshetics(ax, cb=None, cb_label=None):\n",
    "    \"\"\"\n",
    "    Cannot find any rcParam for colorbar-related\n",
    "    axes. Have to go about it this way.\n",
    "    \"\"\"\n",
    "    rc_kw = {'axes.labelsize': 14,\n",
    "             'figure.titlesize': 20,\n",
    "             'figure.facecolor': 'w',\n",
    "             'fontname': 'Helvetica Neue',\n",
    "    }\n",
    "    if cb is not None:\n",
    "        cb.ax.tick_params(labelsize=12)\n",
    "    if cb_label is not None:\n",
    "        cb.set_label(cb_label, fontsize=12)\n",
    "    ax.format(rc_kw=rc_kw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load sample data\n",
    "\n",
    "---\n",
    "\n",
    "`esmtools` contains a folder with post-processed sample data for MPI and CESM ensembles. To avoid supplying massive files, these are computed as global averages."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hindcast\n",
    "\n",
    "---\n",
    "\n",
    "The CESM-DPLE (Community Earth System Model-Decadal Prediction Large Ensemble) is initialized from a forced ocean sea-ice (FOSI) hindcast. This hindcast mainly uses CORE winds (i.e., a data atmosphere), with active (or modeled) ocean and sea ice components. It has been shown to reasonably reproduce historical ocean conditions, including El Ni√±o events.\n",
    "\n",
    "The hindcast output is provided at monthly resolution, but for the purpose of this demo, we will just look at annual means."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_hindcast():\n",
    "    hind = xr.open_dataset('../sample_data/prediction/g.e11_LENS.GECOIAF.T62_g16.009.pop.h.SST.024901-031612.nc')\n",
    "    hind = hind.drop(['z_t', 'time_bound']) # unneeded variables\n",
    "    # Resample to annual means\n",
    "    hind = hind.groupby('time.year').mean('time')\n",
    "    # Same timeframe as dple\n",
    "    hind = hind.sel(year=slice(1955,2015))\n",
    "    hind = hind.rename({'year': 'ensemble'}) # corresponds to language used in package\n",
    "    return hind['SST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hind = _load_hindcast()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The hindcast comes out as raw output, but we want to compare it directly to the anomalies provided by the DPLE. For annual averages, we just subtract the mean of the simulation. For monthly output, we have to remove monthly climatologies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hind = hind - hind.mean('ensemble')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plot.subplots(axwidth=6, aspect=5)\n",
    "ax.plot(hind.ensemble, hind, linewidth=2, color='sea')\n",
    "set_aeshetics(ax)\n",
    "ax.format(xlabel='year', ylabel='SST Anomaly (K)', title='FOSI Hindcast SST')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CESM Decadal Prediction Large Ensemble\n",
    "\n",
    "---\n",
    "\n",
    "Here, we load in the actual initialized CESM-DPLE to compute prediction metrics with (see intro to notebook)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _load_dple():\n",
    "    dple = xr.open_dataset('../sample_data/prediction/CESM-DP-LE.SST.annmean.anom.nc') \\\n",
    "             .rename({'anom': 'SST'})\n",
    "    # Renames to standards expected in this package. This might be incorporated as\n",
    "    # a function, although it's such minimal processing that it should be up to the\n",
    "    # user.\n",
    "    dple = dple.rename({'S':'ensemble','M':'member','L':'time'})\n",
    "    dple = dple.sel(ensemble=slice(1955, 2015))\n",
    "    return dple"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dple = _load_dple()\n",
    "dple_mean = dple.mean('member')['SST']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dple.info()\n",
    "dple = dple['SST'] # easier to work with DataArray since we don't have other variables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Mean Perspective\n",
    "\n",
    "---\n",
    "\n",
    "Here, we are just looking at the structure of the ensemble. We take the ensemble mean (of all 40 members) and plot the prediction lead year vs. the initialization year of the ensemble."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: CHANGE TO PCOLORMESH. PYTHON3.7 ERRORS CURRENTLY WHEN MAKING\n",
    "# A COLORBAR WITH ANYTHING BUT CONTOURS\n",
    "f, ax = plot.subplots(axwidth=4, aspect=1, rightpanel=True)\n",
    "m = ax.contourf(dple_mean.time, dple_mean.ensemble, dple_mean.transpose())\n",
    "cb = f.rightpanel.colorbar(m)\n",
    "set_aeshetics(ax, cb=cb, cb_label='SST Anomaly [K]')\n",
    "ax.format(xlabel='Lead Year', ylabel='Initialization Year', title='DPLE Ensemble Mean SST')\n",
    "cb.ax.tick_params(labelsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lead Year 1 timeseries for all members\n",
    "\n",
    "---\n",
    "\n",
    "Another view of the ensemble. Here, we are only looking at the prediction for one year out, i.e., after the November 1st initialization, what does the annual mean forecast look like for the following year?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plot.subplots(axwidth=6, aspect=5)\n",
    "ax.plot(dple.ensemble, dple.isel(time=0), cycle=('Sunrise', 15))\n",
    "set_aeshetics(ax)\n",
    "ax.format(xlabel='Year', ylabel='SST Anomaly [K]', title='DPLE Lead Year 1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Mean Lead Year Predictions\n",
    "\n",
    "---\n",
    "\n",
    "Here, we take the ensemble mean again, but look at predictions for various lead years from 1 (blue/purple) to 10 (yellow) and compare it to our reference hindcast (thick black line)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plot.subplots(axwidth=6, aspect=5)\n",
    "ax.plot(dple.ensemble, dple.mean('member'), linewidth=1.5, cycle=('Sunrise_r', 10))\n",
    "ax.plot(hind.ensemble, hind, color='k', linewidth=2.5, label='FOSI Hindcast Mean')\n",
    "set_aeshetics(ax)\n",
    "ax.format(xlabel='Year', ylabel='SST Anomaly [K]', title='Lead Year Predictions')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Basic Prediction Metrics\n",
    "\n",
    "---\n",
    "\n",
    "Looking at predictability vs. persistence, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dple_mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "f, ax = plot.subplots(axwidth=6, aspect=5, bottomlegend=True)\n",
    "\n",
    "# Hindcast mean\n",
    "p1 = ax.plot(hind.ensemble, hind, color='k', linewidth=2,\n",
    "             label='hindcast')\n",
    "\n",
    "# DPLE mean\n",
    "p2 = ax.plot(dple.ensemble, dple_mean.isel(time=0), color='rouge', \n",
    "             linewidth=2, label='initialized forecast')\n",
    "\n",
    "f.bottompanel.legend([p1, p2])\n",
    "set_aeshetics(ax)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction module for hindcasts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the comparison functions are basically the same as xr.broadcast (I want \n",
    "# to have forecast and truth in the same dimensions), but it this\n",
    "# implementation here runs at double speed compared to xr.broadcast\n",
    "\n",
    "def _e2a(DPE, assim):\n",
    "    \"\"\"Compare ensemble member mean forecast with assimilation.\"\"\"\n",
    "    fct = DPE.mean('member')\n",
    "    truth = assim.expand_dims('time')\n",
    "    ntime = DPE.time.size\n",
    "    truth = truth.isel(time=[0]*ntime)\n",
    "    truth['time'] = np.arange(1,1+ntime)\n",
    "    return fct, truth\n",
    "\n",
    "def _m2a(DPE, assim):\n",
    "    \"\"\"Compare every ensemble member forecast with assimilation.\"\"\"\n",
    "    fct = DPE\n",
    "    truth = assim.expand_dims('time').expand_dims('member')\n",
    "    ntime = DPE.time.size\n",
    "    nmember = DPE.member.size\n",
    "    truth = truth.isel(member=[0]*nmember,time=[0]*ntime)\n",
    "    truth['time'] = np.arange(1,1+ntime)\n",
    "    truth['member'] = np.arange(1,1+nmember)\n",
    "    return fct, truth\n",
    "\n",
    "def hindcast_compute(DPE, assim, metric=_pearson_r, comparison=_e2a, time_dim='ensemble'):\n",
    "    \"\"\"\n",
    "    Compute a predictability skill score for a perfect-model framework simulation dataset.\n",
    "\n",
    "    Relies on two concepts yielding equal results (see comparisons):\n",
    "    - np vectorized from xskillscore (_rmse, _pearson_r) but manually 'stacked' (_m2m, m2e, ...)\n",
    "    - xarray vectorized (_mse, _rmse_v, ...) from ensemble variance (_ens_var_against_mean, _..control)\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    DPE, assim : Decadal Prediction Ensemble and Assimilation xr.Dataset with\n",
    "                 time_dim dimension (optional spatial coordinates)\n",
    "        input data\n",
    "    metric : function\n",
    "        metric from [_rmse, _pearson_r]\n",
    "    comparison : function\n",
    "        comparison from [_m2a, _e2a]\n",
    "    time_dim : str\n",
    "        Name of the time dimension (likely 'year' or 'time')\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    res : xr.DataArray or xr.Dataset\n",
    "        skill score\n",
    "    \"\"\"\n",
    "    if comparison.__name__ not in ['_e2a', '_m2a']:\n",
    "        raise ValueError('specify comparison argument')\n",
    "\n",
    "    if metric.__name__ in ['_pearson_r', '_rmse']:\n",
    "        fct, truth = comparison(DPE,assim)\n",
    "        res = metric(fct, truth,'ensemble')\n",
    "        if comparison.__name__ is '_m2a':\n",
    "            res = res.mean('member')\n",
    "        return res\n",
    "    else:\n",
    "        raise ValueError('specify metric argument')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Approach for bootstrapping: Shuffle ensemble dimension"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _shuffle_ensembles(DPE):\n",
    "    \"\"\"Shuffle ensemble dimension for bootstrapping.\"\"\"\n",
    "    enslist = DPE.ensemble.values\n",
    "    ens = enslist.copy()\n",
    "    np.random.sample(enslist)\n",
    "    DPE_shuffled = DPE.sel(ensemble=enslist)\n",
    "    DPE_shuffled['ensemble'] = ens\n",
    "    return DPE_shuffled\n",
    "\n",
    "import random\n",
    "def _shuffle(ds,dim='ensemble'):\n",
    "    dimval = ds[dim].values\n",
    "    dimval_new = np.random.permutation(dimval)\n",
    "    ds_shuffled = ds.sel({dim:dimval_new})\n",
    "    if isinstance(ds_shuffled,xr.Dataset):\n",
    "        ds_shuffled = ds_shuffled.assign({dim:dimval})\n",
    "    elif isinstance(ds_shuffled,xr.DataArray):\n",
    "        ds_shuffled[dim] = dimval\n",
    "    return ds_shuffled\n",
    "\n",
    "def hindcast_sig(DPE, assim, metric=_pearson_r, comparison=_e2a, sig=99, bootstrap=300):\n",
    "    \"\"\"\n",
    "    Return sig-th percentile of function to be choosen from shuffled DPE.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    DPE, assim : xr.DataArray/Dataset with time_dim dimension\n",
    "        input data\n",
    "    sig: int or list\n",
    "        Significance level for bootstrapping from pseudo ensemble\n",
    "    bootstrap: int\n",
    "        number of iterations\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    sig_level : xr.DataArray/Dataset as inputs\n",
    "        significance level without time_dim, ensemble and member dimensions\n",
    "        as many sig_level as listitems in sig\n",
    "\n",
    "    \"\"\"\n",
    "    x = []\n",
    "    for _ in range(1 + int(bootstrap / DPE['time'].size)):\n",
    "        ds_pseudo = _shuffle(DPE)\n",
    "        ds_pseudo_metric = hindcast_compute(\n",
    "            ds_pseudo, assim, metric=metric, comparison=comparison)\n",
    "        x.append(ds_pseudo_metric)\n",
    "    ds_pseudo_metric = xr.concat(x, dim='it')\n",
    "    if isinstance(sig, list):\n",
    "        qsig = [x / 100 for x in sig]\n",
    "    else:\n",
    "        qsig = sig / 100\n",
    "    sig_level = ds_pseudo_metric.quantile(q=qsig, dim=['time', 'it'])\n",
    "    return sig_level"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_limit_sig(metric=_pearson_r,sig=99):\n",
    "    if metric.__name__ in ['_pearson_r', '_PPP', '_PM_MSSS']:\n",
    "        limit = 'upper'\n",
    "        sigl = sig\n",
    "    else:\n",
    "        limit = 'lower'\n",
    "        sigl = 100 - sig\n",
    "    return limit, sigl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notes\n",
    "---\n",
    "- I think we are making our coding very difficult with the time_dim argument. Isnt it much easier if we just agree whether to use time or year? Independent of the choice we make, do we need to have this flexible? To me it seems much easier to rename dimensions in the beginning and then just run the code.\n",
    "- Now this code can only compute the metrics ACC and RMSE because those are implemented based on numpy in xskillscore https://github.com/raybellwaves/xskillscore. \n",
    "    - What do you think about adding the few needed metrics by ourselves? MSE, MAE can be probably easily adapted from this.\n",
    "- So far the rest of the prediction module works always on xr.Datasets (and mostly also for xr.DataArrays). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prediction skill"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bootstrap=1000\n",
    "sig=99\n",
    "metric=_pearson_r\n",
    "comparison=_e2a"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## raw anomaly data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DPE.mean('member').to_dataframe()[varname].unstack().plot()\n",
    "assim[varname].plot(lw=3,color='k',label='Assimilation')\n",
    "plt.title('Lead year timeseries and assimilation without removing trend')\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "skill = hindcast_compute(DPE, assim, metric=metric,comparison=comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in [_pearson_r,_rmse]:\n",
    "    limit, sigl = get_limit_sig(metric=metric, sig=sig)\n",
    "    for comparison in [_e2a,_m2a]:\n",
    "        # compute hindcast skill\n",
    "        skill = hindcast_compute(DPE, assim,metric=metric,comparison=comparison)\n",
    "        skill[varname].plot(label=' '+metric.__name__+' '+comparison.__name__)\n",
    "        # bootstrap threshold\n",
    "        threshold = hindcast_sig(DPE,assim, metric=metric,comparison=comparison, bootstrap=bootstrap, sig=sigl)[varname].values\n",
    "        plt.axhline(y=threshold, ls=':',c='gray',label='bootstrap n='+str(bootstrap)+' threshold '+str(sig)+'% significance')\n",
    "        ph = xr_predictability_horizon(skill, threshold, limit=limit)[varname].values\n",
    "        plt.axvline(x=ph,ls='-.',c='gray',label='Predictability Horizon')\n",
    "    plt.legend()\n",
    "    plt.title(metric.__name__+' Skill Score without removing trend')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "quite high (artificial) ACC prediction skill due to climate change forcing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detrend by linear fit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=1\n",
    "detrended_DPE = esmtools.stats.xr_rm_poly(DPE[varname],n, dim='ensemble').to_dataset(varname)\n",
    "detrended_assim = esmtools.stats.xr_rm_poly(assim[varname],n, dim='ensemble').to_dataset(varname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "detrended_DPE.mean('member').to_dataframe()[varname].unstack().plot()\n",
    "detrended_assim.to_dataframe()[varname].plot(lw=3,color='k',label='Assimilation')\n",
    "plt.legend()\n",
    "plt.title('Lead year timeseries and assimilation after removing linear trend')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "probably a 2nd order polynomial does better"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in [_pearson_r,_rmse]:\n",
    "    limit, sigl = get_limit_sig(metric=metric, sig=sig)\n",
    "    for comparison in [_e2a,_m2a]:\n",
    "        # compute hindcast skill\n",
    "        skill = hindcast_compute(detrended_DPE, detrended_assim,metric=metric,comparison=comparison)\n",
    "        skill[varname].plot(label=' '+metric.__name__+' '+comparison.__name__)\n",
    "        # bootstrap threshold\n",
    "        threshold = hindcast_sig(detrended_DPE,detrended_assim, metric=metric, comparison=comparison, bootstrap=bootstrap, sig=sigl)[varname].values\n",
    "        plt.axhline(y=threshold, ls=':',c='gray',label='bootstrap n='+str(bootstrap)+' threshold '+str(sig)+'% significance')\n",
    "        ph = xr_predictability_horizon(skill, threshold, limit=limit)[varname].values\n",
    "        plt.axvline(x=ph,ls='-.',c='gray',label='Predictability Horizon')\n",
    "    plt.legend()\n",
    "    plt.title(metric.__name__+' Skill Score after removing linear trend')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## detrend via n-th order polynomial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n=2\n",
    "polyndetrended_DPE = esmtools.stats.xr_rm_poly(DPE[varname],n, dim='ensemble').to_dataset(varname)\n",
    "polyndetrended_assim = esmtools.stats.xr_rm_poly(assim[varname],n, dim='ensemble').to_dataset(varname)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "polyndetrended_DPE.mean('member').to_dataframe()[varname].unstack().plot()\n",
    "detrended_assim.to_dataframe()[varname].plot(lw=3,color='k',label='Assimilation')\n",
    "plt.legend()\n",
    "plt.title('Lead year timeseries and assimilation after removing n-th order polynomial trend')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for metric in [_pearson_r,_rmse]:\n",
    "    limit, sigl = get_limit_sig(metric=metric, sig=sig)\n",
    "    for comparison in [_e2a,_m2a]:\n",
    "        # compute hindcast skill\n",
    "        skill = hindcast_compute(polyndetrended_DPE, polyndetrended_assim,metric=metric,comparison=comparison)\n",
    "        skill[varname].plot(label=' '+metric.__name__+' '+comparison.__name__)\n",
    "        # bootstrap threshold\n",
    "        threshold = hindcast_sig(polyndetrended_DPE, polyndetrended_assim, metric=metric, comparison=comparison, bootstrap=bootstrap, sig=sigl)[varname].values\n",
    "        plt.axhline(y=threshold, ls=':',c='gray',label='bootstrap n='+str(bootstrap)+' threshold '+str(sig)+'% significance')\n",
    "        ph = xr_predictability_horizon(skill, threshold, limit=limit)[varname].values\n",
    "        plt.axvline(x=ph,ls='-.',c='gray',label='Predictability Horizon')\n",
    "    plt.legend()\n",
    "    plt.title(metric.__name__+' Skill Score after removing linear trend')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  detrend via unitialised ensemble mean from CESM LE \n",
    "that should be nice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
